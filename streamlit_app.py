# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13Gew5CkCfZTTbmWjaIwMXfN7_V3Jnobr
"""

import gradio as gr
import pandas as pd
import spacy
import numpy as np
from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.ensemble import RandomForestClassifier
import re
import nltk
from nltk.corpus import stopwords
from scipy.stats import randint

nltk.download('stopwords')
stop_words = set(stopwords.words('english'))

# Load the spaCy model
nlp = spacy.load("en_core_web_md")

def get_spacy_embedding(text, nlp):
    """Gets the document embedding from spaCy."""
    doc = nlp(text)
    return doc.vector

def clean_instruction(text):
    if pd.isna(text):
        return ""

    # Remove URLs
    text = re.sub(r'http\S+', '', text)

    # Remove HTML tags
    text = re.sub(r'<.*?>', '', text)

    # Remove punctuation
    text = re.sub(r'[^\w\s]', '', text)

    # Convert to lowercase
    text = text.lower()

    # Remove stop words
    text = ' '.join([word for word in text.split() if word not in stop_words])

    # Remove extra spaces and line breaks
    text = ' '.join(text.split())

    # Tokenize the text
    tokens = text.split()

    # Fix contractions (example - you'll need the contractions library)
    # tokens = [contractions.fix(word) for word in tokens]

    return ' '.join(tokens)  # Return the cleaned text

# Load and preprocess your data
df = pd.read_csv("Mydataset.csv")

# Apply cleaning and preprocessing to the entire DataFrame
df['clean_instruction'] = df['instruction'].apply(clean_instruction)

# Generate embeddings for the entire dataset
df['embeddings'] = df['clean_instruction'].apply(lambda x: get_spacy_embedding(x, nlp))

# Prepare feature and target variables
X = np.vstack(df['embeddings'].values)
y = df['category']

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Define the parameter distributions for RandomizedSearchCV
param_dist = {
    'n_estimators': randint(5, 10),
    'max_depth': randint(5, 10),
    'min_samples_split': randint(2, 20),
    'min_samples_leaf': randint(1, 20),
    'max_features': ['sqrt', 'log2'],
    'class_weight': ['balanced', None]
}

# Create a Random Forest classifier
rf = RandomForestClassifier(random_state=42)

# Use RandomizedSearchCV
random_search = RandomizedSearchCV(
    estimator=rf,
    param_distributions=param_dist,
    n_iter=10,
    cv=2,
    scoring='accuracy',
    n_jobs=-1,
    random_state=42
)

# Fit the RandomizedSearchCV object on the original data (before resampling)
random_search.fit(X_train, y_train)

# Get the best model and its predictions
best_rf_model = random_search.best_estimator_

def predict_category(query):
    greetings = ["hi", "hello", "hey", "good morning", "good evening", "how are you"]
    if any(greeting in query.lower() for greeting in greetings):
        return "GREETING", gr.update(visible=False)
    else:
        try:
            cleaned_instruction = clean_instruction(query)
            cleaned_instruction = cleaned_instruction.replace("order number", "")

            if not cleaned_instruction:
                raise ValueError("Invalid query: Please provide a valid query.")

            df_pred = pd.DataFrame({'clean_instruction': [cleaned_instruction]})

            df_pred['embeddings'] = df_pred['clean_instruction'].apply(lambda x: get_spacy_embedding(x, nlp))
            X_pred = np.vstack(df_pred['embeddings'].values)

            # Use the best Random Forest model for prediction
            prediction = best_rf_model.predict(X_pred)[0]

            return prediction, gr.update(visible=False)

        except ValueError as e:
            return str(e), gr.update(visible=True)
        except Exception as e:
            error_message = "Error occurred while classifying your query! Please try again or contact support."
            return error_message, gr.update(visible=True)

# Create the Gradio interface (single page)
with gr.Blocks(css="""
    body {
        background-color: #e6ffe6 !important; /* Light faded green background */
    }
    #query_input {
        background-color: #f0fff0 !important;
        border: 2px solid #90ee90 !important;
        border-radius: 10px !important;
        font-family: 'Verdana', sans-serif !important;
        font-size: 16px !important;
        font-weight: bold !important;
    }
    #submit_button {
        background-color: #007bff !important; /* Blue background */
        border: 2px solid #0056b3 !important; /* Darker blue border */
        border-radius: 10px !important;
        font-family: 'Courier New', monospace !important;
        font-size: 14px !important;
        font-weight: 600 !important;
        color: white !important; /* White text color */
    }
     #predicted_category {
        background-color: #E6E6FA !important;
        border: 3px solid #90ee90 !important;
        border-radius: 10px !important;
        font-family: 'Verdana', sans-serif !important;
        font-size: 16px !important;
        font-weight: bold !important;
    }
    .gr-textbox:nth-of-type(2) {
        background-color: #ffffff !important;
        border: 2px solid #ffa500 !important;
        color: #ffa500 !important;
    }
""") as iface:
    gr.Markdown("<h1 style='text-align: center; color: #004d00;'>How can we assist you?</h1>")

    with gr.Row():
        query_input = gr.Textbox(
            label="Query",
            lines=2,
            placeholder="Please type your Query...",
            elem_id="query_input",)
        submit_button = gr.Button("Submit", elem_id="submit_button") 

    predicted_category = gr.Textbox(label="Predicted Category")
    error_message = gr.HTML(
        "<p style='color: red;'>Error occurred while classifying your query! Please try again or contact support.</p>",
        visible=False,
    )

    submit_button.click(
        fn=predict_category,
        inputs=query_input,
        outputs=[predicted_category, error_message],
    )

iface.launch()